{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c0f1ff-b9ef-4540-b815-d8b69f9b5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b3d88d8f-8211-4319-9d40-1ba02600d453",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'enable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_trf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Accomodating longer sentences\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nlp\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000000\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'enable'"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Accomodating longer sentences\n",
    "nlp.max_length = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c78dd36-2e8a-44bd-86b7-281a92d24281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer',\n",
       "  <spacy_transformers.pipeline_component.Transformer at 0x7fc211947e80>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7fc210d59240>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7fc210297220>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7fc2106a0800>),\n",
       " ('lemmatizer',\n",
       "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7fc2101e3e40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7fc210297f40>)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "294af0a4-d008-42df-af4e-a81429e3a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"custom_sentencizer\")\n",
    "def custom_sentencizer(doc: str) -> object:\n",
    "    \"\"\" Custom sentencizer to ignore brackets as sentence boundaries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        Text to process.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doc : spacy.Doc\n",
    "        spacy document with sentence boundaries.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    \"\"\"\n",
    "    # Exception tokens\n",
    "    exceptions = [\"mr.\", \"ms.\", \"mrs.\", \"adv.\", \"advs.\", \"sr.\",\n",
    "                  \"dr.\", \"m.\", \"crl.\", \"a.\", \"advocate.\", \"advocates.\",\n",
    "                  \"w.\", \"p.\", \"fir.\", \"ltd.\"]\n",
    "\n",
    "    # The last token cannot start a sentence\n",
    "    for i, token in enumerate(doc[:-2]):\n",
    "        \n",
    "        if token.text[-1] in \".?!:\":\n",
    "\n",
    "            doc[i+1].is_sent_start = True\n",
    "            \n",
    "            num_punct = sum([char in \".?!:\" for char in token.text])\n",
    "            \n",
    "            if  num_punct > 1 and num_punct < len(token.text):\n",
    "                doc[i+1].is_sent_start = False\n",
    "            \n",
    "            if not doc[i+1].text[0].isupper():\n",
    "                doc[i+1].is_sent_start = False\n",
    "\n",
    "            if doc[i+1].text[-1] == '.' and len(doc[i+1].text) == 2:\n",
    "                doc[i+1].is_sent_start = False\n",
    "                \n",
    "            if doc[i].text[-1] == '.' and len(doc[i].text) == 2:\n",
    "                doc[i+1].is_sent_start = False\n",
    "\n",
    "            if token.text.lower() in exceptions:\n",
    "                doc[i+1].is_sent_start = False\n",
    "\n",
    "            if (doc[i].is_sent_start is True):\n",
    "                doc[i+1].is_sent_start = False\n",
    "                \n",
    "    doc[-1].is_sent_start = False\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2c05b78f-bc43-4069-878d-d0c451101a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_1 = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "70d33b9b-c6fd-49b4-95dc-ed8b4a8ca178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.custom_sentencizer(doc: str) -> object>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_1.add_pipe(\"custom_sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2ecf0eb4-3d7b-4bae-aaf6-224abacccfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('custom_sentencizer',\n",
       "  <function __main__.custom_sentencizer(doc: str) -> object>)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_1.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9633b9b2-5605-40ae-82d0-638d31cd1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"This is a test. Will the sentencizer work?\", \"This is a second sentence where A.K. Rampur went somewhere.           .... This is bad english I.P.C. is a code of conduct okay?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b44bb3d8-aa94-407d-902e-8a49682cb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_nlp = nlp_1.pipe(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "35f8addf-6e1c-43e5-a343-6d7ceae4e22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n",
      "Will the sentencizer work?\n",
      "This is a second sentence where A.K. Rampur went somewhere.           ....\n",
      "This is bad english I.P.C. is a code of conduct okay?\n"
     ]
    }
   ],
   "source": [
    "for t in nlp_1.pipe(sent):\n",
    "    for s in t.sents:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a59f8c5-1308-445c-a253-fcf72d0abd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sent_nlp:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1f9c5-83fd-4625-b70f-30edf2b8e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
